{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YOLOV7.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP/3lls6XfPXxBOu3t4d1zK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/naksh-atra/Theory/blob/main/YOLOV7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "byxdKmIpEcCn"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "YOLO Real-Time Object Detection\n",
        "What is real-time object detection?\n",
        "In computer vision, real-time object detection is a very important task that is often a key component in computer vision systems. Applications that use real-time object detection models include video analytics, robotics, autonomous vehicles, multi-object tracking and object counting, medical image analysis, and so on.\n",
        "\n",
        "An object detector is an object detection algorithm that performs image recognition tasks by taking an image as input and then predicting bounding boxes and class probabilities for each object in the image (see the example image below). Most algorithms use a convolutional neural network (CNN) to extract features from the image to predict the probability of learned classes.\n",
        "\n",
        " \n",
        "\n",
        "applications of computer vision in aviation\n",
        "YOLOv7 applied for computer vision in Aviation – built on Viso Suite\n",
        " \n",
        "\n",
        "What is YOLO in computer vision?\n",
        "YOLO stands for “You Only Look Once”, it is a popular family of real-time object detection algorithms. The original YOLO object detector was first released in 2016. It was created by Joseph Redmon, Ali Farhadi, and Santosh Divvala. At release, this architecture was much faster than other object detectors and became state-of-the-art for real-time computer vision applications.\n",
        "\n",
        "Since then, different versions and variants of YOLO have been proposed, each providing a significant increase in performance and efficiency. The versions from YOLOv1 to the popular YOLOv3 were created by then-graduate student Joseph Redmon and advisor Ali Farhadi. YOLOv4 was introduced by Alexey Bochkovskiy, who continued the legacy since Redmon had stopped his computer vision research due to ethical concerns.\n",
        "\n",
        "YOLOv7 is the latest official YOLO version created by the original authors of the YOLO architecture. We expect that many commercial networks will move directly from YOLOv4 to v7, bypassing all the other numbers.\n",
        "\n",
        " \n",
        "\n",
        "Unofficial YOLO versions\n",
        "There were some controversies in the computer vision community whenever other researchers and companies published their models as YOLO versions. A popular example is YOLOv5 which was created by the company Ultralytics. It’s similar to YOLOv4 but uses a different framework, PyTorch, instead of DarkNet. However, the creator of YOLOv4, Alexey Bochkovskiy provided benchmarks comparing YOLOv4 vs. YOLOv5, showing that v4 is equal or better.\n",
        "\n",
        "Another example is YOLOv6 which was published by the Chinese company Meituan (hence the MT prefix of YOLOv6). And there is also an unofficial YOLOv7 version that was released in the year before the official YOLOv7 (there are two YOLOv7’s).\n",
        "\n",
        "Both YOLOv5 and YOLOv6 are not considered part of the official YOLO series but were heavily inspired by the original one-stage YOLO architecture. Critics argue that companies try to benefit from the YOLO hype and that the papers were not adequately peer-reviewed. Hence, some say that the official YOLOv7 should be the real YOLOv5.\n",
        "\n",
        " \n",
        "\n",
        "YOLOv7 object detection in a dense scene\n",
        "YOLOv7 object detection in a dense scene – Viso Suite\n",
        " \n",
        "\n",
        "Real-time object detectors and YOLO versions\n",
        "Currently, state-of-the-art real-time object detectors are mainly based on YOLO and FCOS (Fully Convolutional One-Stage Object Detection). The best performing object detectors are:\n",
        "\n",
        "YOLOv3 model, introduced by Redmon et al. in 2018\n",
        "YOLOv4 model, released by Bochkovskiy et al. in 2020,\n",
        "YOLOv4-tiny model, research published in 2021\n",
        "YOLOR (You Only Learn One Representation) model, published in 2021\n",
        "YOLOX model, published in 2021\n",
        "NanoDet-Plus model, published in 2021\n",
        "PP-YOLOE, an industrial object detector, published in 2022\n",
        "YOLOv5 model v6.1 published by Ultralytics in 2022\n",
        "YOLOv7, published in 2022\n",
        " \n",
        "\n",
        "How to run object detection efficiently at the Edge\n",
        "Running object detection in real-world computer vision applications is hard. Key challenges include the allocation of computing resources, system robustness, scalability, efficiency, and latency. In addition, ML computer vision requires IoT communication (see AIoT) for data streaming with images as input and detections as output.\n",
        "\n",
        "To overcome those challenges, the concept of Edge AI has been introduced, which leverages Edge Computing with Machine Learning (Edge ML, or Edge Intelligence). Edge AI modes ML processing from the cloud closer to the data source (camera). Thus, Edge AI applications form distributed edge systems with multiple, connected edge devices or virtual edge nodes (MEC or cloud)."
      ],
      "metadata": {
        "id": "52q2E8gjEis8"
      }
    }
  ]
}
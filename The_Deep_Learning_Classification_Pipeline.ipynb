{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMiAQ4DExGrwuUfgSZcUQLq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/naksh-atra/Theory/blob/main/The_Deep_Learning_Classification_Pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9kvG8FBoHUlC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Based on our previous two sections on image classification and types of learning algorithms, you might be starting to feel a bit steamrolled with new terms, considerations, and what looks to be an insurmountable amount of variation in building an image classifier, but the truth is that building an image classifier is fairly straightforward, once you understand the process.\n",
        "\n",
        "\n",
        "In this section, we’ll review an important shift in mindset you need to take on when working with machine learning. From there I’ll review the four steps of building a deep learning-based image classifier as well as compare and contrast traditional feature-based machine learning versus end-to-end deep learning.\n",
        "\n",
        "A Shift in Mindset\n",
        "Before we get into anything complicated, let’s start off with something that we’re all (most likely) familiar with: the Fibonacci sequence.\n",
        "\n",
        "The Fibonacci sequence is a series of numbers where the next number of the sequence is found by summing the two integers before it. For example, given the sequence 0, 1, 1, the next number is found by adding 1 + 1 = 2. Similarly, given 0, 1, 1, 2, the next integer in the sequence is 1 + 2 = 3.\n",
        "\n",
        "Following that pattern, the first handful of numbers in the sequence are as follows:\n",
        "\n",
        "0, 1, 1, 2, 3, 5, 8, 13, 21, 34, ...\n",
        "Of course, we can also define this pattern in an (extremely unoptimized) Python function using recursion:\n",
        "\n",
        "The Deep Learning Classification Pipeline\n",
        ">>> def fib(n):\n",
        "...     if n == 0:\n",
        "...             return 0\n",
        "...     elif n == 1:\n",
        "...             return 1\n",
        "...     else:\n",
        "...             return fib(n-1) + fib(n-2)\n",
        "...\n",
        ">>>\n",
        "Using this code, we can compute the n-th number in the sequence by supplying a value of n to the fib function. For example, let’s compute the 7th number in the Fibonacci sequence:\n",
        "\n",
        "The Deep Learning Classification Pipeline\n",
        ">>> fib(7)\n",
        "13\n",
        "And the 13th number:\n",
        "\n",
        "The Deep Learning Classification Pipeline\n",
        ">>> fib(13)\n",
        "233\n",
        "And finally the 35th number:\n",
        "\n",
        "The Deep Learning Classification Pipeline\n",
        ">>> fib(35)\n",
        "9227465\n",
        "As you can see, the Fibonacci sequence is straightforward and is an example of a family of functions that:\n",
        "\n",
        "Accepts an input, returns an output.\n",
        "The process is well defined.\n",
        "The output is easily verifiable for correctness.\n",
        "Lends itself well to code coverage and test suites.\n",
        "In general, you’ve probably written thousands upon thousands of procedural functions like these in your life. Whether you’re computing a Fibonacci sequence, pulling data from a database, or calculating the mean and standard deviation from a list of numbers, these functions are all well defined and easily verifiable for correctness.\n",
        "\n",
        "Unfortunately, this is not the case for deep learning and image classification!\n",
        "\n",
        "Notice the pictures of a cat and a dog in Figure 1. Now, imagine trying to write a procedural function that can not only tell the difference between these two photos, but any photo of a cat and a dog. How would you go about accomplishing this task? Would you check individual pixel values at various (x, y)-coordinates? Write hundreds of if/else statements? And how would you maintain and verify the correctness of such a massive rule-based system? The short answer is: you don’t.\n",
        "\n",
        "\n",
        "Figure 1: How might you go about writing a piece of software to recognize the difference between dogs and cats in images? Would you inspect individual pixel values? Take a rule-based approach? Try to write (and maintain) hundreds of if/else statements?\n",
        "Unlike coding up an algorithm to compute the Fibonacci sequence or sort a list of numbers, it’s not intuitive or obvious how to create an algorithm to tell the difference between pictures of cats and dogs. Therefore, instead of trying to construct a rule-based system to describe what each category “looks like,” we can instead take a data-driven approach by supplying examples of what each category looks like and then teach our algorithm to recognize the difference between the categories using these examples.\n",
        "\n",
        "We call these examples our training dataset of labeled images, where each data point in our training dataset consists of:\n",
        "\n",
        "An image\n",
        "The label/category (i.e., dog, cat, panda, etc.) of the image\n",
        "Again, it’s important that each of these images have labels associated with them because our supervised learning algorithm will need to see these labels to “teach itself” how to recognize each category. Keeping this in mind, let’s go ahead and work through the four steps to constructing a deep learning model.\n",
        "\n",
        "Step #1: Gather Your Dataset\n",
        "The first component of building a deep learning network is to gather our initial dataset. We need the images themselves as well as the labels associated with each image. These labels should come from a finite set of categories, such as: categories = dog, cat, panda.\n",
        "\n",
        "Furthermore, the number of images for each category should be approximately uniform (i.e., the same number of examples per category). If we have twice the number of cat images than dog images, and five times the number of panda images than cat images, then our classifier will become naturally biased to overfitting into these heavily-represented categories.\n",
        "\n",
        "Class imbalance is a common problem in machine learning and there exist a number of ways to overcome it. We’ll discuss some of these methods later in this book, but keep in mind the best method to avoid learning problems due to class imbalance is to simply avoid class imbalance entirely.\n",
        "\n",
        "Step #2: Split Your Dataset\n",
        "Now that we have our initial dataset, we need to split it into two parts:\n",
        "\n",
        "A training set\n",
        "A testing set\n",
        "A training set is used by our classifier to “learn” what each category looks like by making predictions on the input data and then correct itself when predictions are wrong. After the classifier has been trained, we can evaluate the performing on a testing set.\n",
        "\n",
        "It’s extremely important that the training set and testing set are independent of each other and do not overlap! If you use your testing set as part of your training data, then your classifier has an unfair advantage since it has already seen the testing examples before and “learned” from them. Instead, you must keep this testing set entirely separate from your training process and use it only to evaluate your network.\n",
        "\n",
        "Common split sizes for training and testing sets include 66.6%/33.3%, 75%/25%, and 90%/10%, respectively (Figure 2):\n",
        "\n",
        "\n",
        "Figure 2: Examples of common training and testing data splits.\n",
        "These data splits make sense, but what if you have parameters to tune? Neural networks have a number of knobs and levers (e.g., learning rate, decay, regularization, etc.) that need to be tuned and dialed to obtain optimal performance. We’ll call these types of parameters hyperparameters, and it’s critical that they get set properly.\n",
        "\n",
        "In practice, we need to test a bunch of these hyperparameters and identify the set of parameters that works the best. You might be tempted to use your testing data to tweak these values, but again, this is a major no-no! The test set is only used in evaluating the performance of your network.\n",
        "\n",
        "Instead, you should create a third data split called the validation set. This set of the data (normally) comes from the training data and is used as “fake test data” so we can tune our hyperparameters. Only after have we determined the hyperparameter values using the validation set do we move on to collecting final accuracy results in the testing data.\n",
        "\n",
        "We normally allocate roughly 10-20% of the training data for validation. If splitting your data into chunks sounds complicated, it’s actually not. As we’ll see in our next chapter, it’s quite simple and can be accomplished with only a single line of code thanks to the scikit-learn library.\n",
        "\n",
        "Step #3: Train Your Network\n",
        "Given our training set of images, we can now train our network. The goal here is for our network to learn how to recognize each of the categories in our labeled data. When the model makes a mistake, it learns from this mistake and improves itself.\n",
        "\n",
        "So, how does the actual “learning” work? In general, we apply a form of gradient descent that we detail in a separate post.\n",
        "\n",
        "Step #4: Evaluate\n",
        "Last, we need to evaluate our trained network. For each of the images in our testing set, we present them to the network and ask it to predict what it thinks the label of the image is. We then tabulate the predictions of the model for an image in the testing set.\n",
        "\n",
        "Finally, these model predictions are compared to the ground-truth labels from our testing set. The ground-truth labels represent what the image category actually is. From there, we can compute the number of predictions our classifier got correct and compute aggregate reports such as precision, recall, and f-measure, which are used to quantify the performance of our network as a whole.\n",
        "\n",
        "Feature-based Learning versus Deep Learning for Image Classification\n",
        "In the traditional, feature-based approach to image classification, there is actually a step inserted between Step #2 and Step #3 — this step is feature extraction. During this phase, we apply hand-engineered algorithms such as HOG, LBPs, etc., to quantify the contents of an image based on a particular component of the image we want to encode (i.e., shape, color, texture). Given these features, we then proceed to train our classifier and evaluate it.\n",
        "\n",
        "When building Convolutional Neural Networks, we can actually skip the feature extraction step. The reason for this is because CNNs are end-to-end models. We present the raw input data (pixels) to the network. The network then learns filters inside its hidden layers that can be used to discriminate amongst object classes. The output of the network is then a probability distribution over class labels.\n",
        "\n",
        "One of the exciting aspects of using CNNs is that we no longer need to fuss over hand-engineered features — we can let our network learn the features instead. However, this tradeoff does come at a cost. Training CNNs can be a non-trivial process, so be prepared to spend considerable time familiarizing yourself with the experience and running many experiments to determine what does and does not work."
      ],
      "metadata": {
        "id": "rm9-ds1tH-4A"
      }
    }
  ]
}